{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2595a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Embedding\n",
    "from configs import *\n",
    "from fetch_data import *\n",
    "from features_extraction import *\n",
    "from data_shuffling_split import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *\n",
    "from keras_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8deed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in the file are:  449033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialect</th>\n",
       "      <th>dialect_l_encoded</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056552188082716800</td>\n",
       "      <td>LY</td>\n",
       "      <td>8</td>\n",
       "      <td>توا دوشه الكلاسيكو شن بيتمها وشن بيسكتهم وشن ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>891734969202114560</td>\n",
       "      <td>SY</td>\n",
       "      <td>15</td>\n",
       "      <td>حسابشخصي في احلي من الشحاطه 😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110565179257954432</td>\n",
       "      <td>SD</td>\n",
       "      <td>14</td>\n",
       "      <td>حسابشخصي موهبه والله 😂 اوع تحاول تطورها تقوم م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1172817955270340608</td>\n",
       "      <td>LB</td>\n",
       "      <td>7</td>\n",
       "      <td>حسابشخصي حسابشخصي 😂 انا صرلي عشر سنين مش مجدده...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293253217821790208</td>\n",
       "      <td>QA</td>\n",
       "      <td>12</td>\n",
       "      <td>احلي شعور تكون باجازه وتقوم من الصبح وتمر ع ال...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id dialect  dialect_l_encoded  \\\n",
       "0  1056552188082716800      LY                  8   \n",
       "1   891734969202114560      SY                 15   \n",
       "2  1110565179257954432      SD                 14   \n",
       "3  1172817955270340608      LB                  7   \n",
       "4   293253217821790208      QA                 12   \n",
       "\n",
       "                                                text  \n",
       "0  توا دوشه الكلاسيكو شن بيتمها وشن بيسكتهم وشن ب...  \n",
       "1                     حسابشخصي في احلي من الشحاطه 😂   \n",
       "2  حسابشخصي موهبه والله 😂 اوع تحاول تطورها تقوم م...  \n",
       "3  حسابشخصي حسابشخصي 😂 انا صرلي عشر سنين مش مجدده...  \n",
       "4  احلي شعور تكون باجازه وتقوم من الصبح وتمر ع ال...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set = read_csv(\"train/strat_train_set.csv\")\n",
    "strat_train_set = strat_train_set.iloc[:5000]\n",
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9dd098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances in the training data after StratifiedShuffleSplit are:  4900\n",
      "The number of instances in the testing data after StratifiedShuffleSplit are:   100\n",
      "The number of trainin instances:  4900\n",
      "The number of validation instances:  100\n",
      "The number of trainin labels :  4900\n",
      "The number of validation labels :  100\n"
     ]
    }
   ],
   "source": [
    "x_train_text, x_val_text, y_train, y_val = prepare_data(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0507dbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenization : \n",
      " ['حسابشخصي الله يحشرك واللي وراك معاه بنار جهنم تحرقكم سواد وجوهكم اكثر من ما هي سودا . . . شواذي 🐒 ', 'حسابشخصي متفكريناش صافي زعما سالات العطله 😥 ', 'حاشرين نفسكم في اي بطيخ رابطويب']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['حسابشخصي', 'الله', 'يحشرك', 'واللي', 'وراك', 'معاه', 'بنار', 'جهنم', 'تحرقكم', 'سواد', 'وجوهكم', 'اكثر', 'من', 'ما', 'هي', 'سودا', '.', '.', '.', 'شواذي', '🐒'], ['حسابشخصي', 'متفكريناش', 'صافي', 'زعما', 'سالات', 'العطله', '😥'], ['حاشرين', 'نفسكم', 'في', 'اي', 'بطيخ', 'رابطويب']]\n",
      "==================================================\n",
      "Before Tokenization : \n",
      " ['الف الف مبرووك ياشبااب 💚 ', 'حسابشخصي حسابشخصي قمر لو كمره هه', 'حسابشخصي حسابشخصي تري اطلع ملفك من محكمه البحرين واخرته من اهلك ام عبير 😂 ماعاد الا جزيره الريتويت انتم اصلا محد يدري عنكم . . ']\n",
      "==================================================\n",
      "After Tokenization : \n",
      " [['الف', 'الف', 'مبرووك', 'ياشبااب', '💚'], ['حسابشخصي', 'حسابشخصي', 'قمر', 'لو', 'كمره', 'هه'], ['حسابشخصي', 'حسابشخصي', 'تري', 'اطلع', 'ملفك', 'من', 'محكمه', 'البحرين', 'واخرته', 'من', 'اهلك', 'ام', 'عبير', '😂', 'ماعاد', 'الا', 'جزيره', 'الريتويت', 'انتم', 'اصلا', 'محد', 'يدري', 'عنكم', '.', '.']]\n"
     ]
    }
   ],
   "source": [
    "x_train_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_train_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_train_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_train_text_tokenized[:3])\n",
    "print(\"=\"*50)\n",
    "\n",
    "x_val_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_val_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_val_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_val_text_tokenized[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48ed7e",
   "metadata": {},
   "source": [
    "# LSTM Model with Bakr Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc85e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/bakrianoo_unigram_cbow_model/full_uni_cbow_100_twitter.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3316ece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "(4900, 64, 100)\n",
      "(4900, 6400)\n",
      "==================================================\n",
      "[ 5.44    -1.274    3.229   -3.773   -3.795    4.926   -0.6597   2.365\n",
      "  0.5625  -3.352    0.3213   0.5005  -3.709   -5.33     3.615    1.654\n",
      "  2.988   -0.7603   0.3733   2.418   -2.904   -2.7      2.135   -0.3982\n",
      "  0.63     1.314   -0.8735   4.855    4.684   -1.277    3.67    -2.932\n",
      "  2.867    2.352    2.062   -0.756   -2.1      5.863    0.9263  -0.7715\n",
      "  0.5312   4.836   -0.761   -0.4324  -3.611   -1.574    0.10724 -3.316\n",
      " -1.546    3.238  ]\n",
      "==================================================\n",
      "(100, 64, 100)\n",
      "(100, 6400)\n",
      "==================================================\n",
      "[-5.2197e-01 -3.3154e-01  3.4512e+00  1.1807e+00  4.6753e-01 -1.2539e+00\n",
      "  8.2861e-01  3.2012e+00 -8.2764e-01  3.2363e+00 -1.9795e+00 -4.4961e+00\n",
      " -3.3965e+00 -4.1953e+00 -6.5674e-01  1.0615e+00 -2.7148e+00  7.0352e+00\n",
      " -3.2754e+00 -2.6641e+00 -1.9702e-01  1.3691e+00  3.8354e-01  3.5625e+00\n",
      "  5.5469e-01 -5.5078e-01 -2.3594e+00  3.8330e-01  9.3311e-01 -5.9912e-01\n",
      " -2.7500e+00  7.1240e-01  1.2734e+00 -4.3848e-01 -4.6997e-01 -7.8516e-01\n",
      " -1.2666e+00  2.4297e+00 -1.8193e+00  1.1855e+00 -3.5996e+00  1.2344e+00\n",
      "  5.1406e+00  1.5984e-03 -3.0176e+00 -1.9160e+00  4.3711e+00  2.4219e+00\n",
      "  2.2383e+00 -1.0358e-01]\n"
     ]
    }
   ],
   "source": [
    "max_len_str = 64\n",
    "hid_num_neurons = 50\n",
    "learning_rate = .1\n",
    "epochs = 30\n",
    "\n",
    "performance_lr = keras.callbacks.ReduceLROnPlateau(factor=.5, patience=5)\n",
    "SGD_optimizer     =keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "Adam_optimizer = keras.optimizers.Adam(beta_1=0.9, beta_2=0.999)\n",
    "RMSprop_optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate, rho=.9)\n",
    "\n",
    "\n",
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "\n",
    "number_of_features = 100\n",
    "word2vec_path = \"bakr/\"\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "\n",
    "# Reshape because of deep learning model\n",
    "X_train_embed_matrix = X_train_embed_matrix.reshape(X_train_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "X_val_embed_matrix = X_val_embed_matrix.reshape(X_val_embed_matrix.shape[0], max_len_str, number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a969b",
   "metadata": {},
   "source": [
    "# With  SGD and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a518130a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 64, 50)            30200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 87,818\n",
      "Trainable params: 87,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"sgd_lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7c44b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 6s 28ms/step - loss: 2.5555 - accuracy: 0.2055 - val_loss: 2.2764 - val_accuracy: 0.2600\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 2.1528 - accuracy: 0.3241 - val_loss: 2.3268 - val_accuracy: 0.2400\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 1.9022 - accuracy: 0.3953 - val_loss: 2.3028 - val_accuracy: 0.2700\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 1.6945 - accuracy: 0.4651 - val_loss: 2.2819 - val_accuracy: 0.3000\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 1.5218 - accuracy: 0.5304 - val_loss: 2.3182 - val_accuracy: 0.3100\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 1.3570 - accuracy: 0.5884 - val_loss: 2.4854 - val_accuracy: 0.2800\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d598e7af",
   "metadata": {},
   "source": [
    "# With  Adam and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c6d63a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64, 50)            30200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 87,818\n",
      "Trainable params: 87,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"Adam_lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "718f4bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 6s 29ms/step - loss: 2.5348 - accuracy: 0.2039 - val_loss: 2.2425 - val_accuracy: 0.2700\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 2.0438 - accuracy: 0.3549 - val_loss: 2.2127 - val_accuracy: 0.3100\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 1.7476 - accuracy: 0.4480 - val_loss: 2.1682 - val_accuracy: 0.3200\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 4s 26ms/step - loss: 1.5219 - accuracy: 0.5278 - val_loss: 2.1900 - val_accuracy: 0.3500\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 4s 26ms/step - loss: 1.3329 - accuracy: 0.5880 - val_loss: 2.2618 - val_accuracy: 0.3400\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 1.1610 - accuracy: 0.6455 - val_loss: 2.3278 - val_accuracy: 0.3400\n",
      "Epoch 7/30\n",
      "154/154 [==============================] - 4s 26ms/step - loss: 1.0069 - accuracy: 0.7018 - val_loss: 2.5368 - val_accuracy: 0.3200\n",
      "Epoch 8/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 0.8770 - accuracy: 0.7345 - val_loss: 2.6374 - val_accuracy: 0.3200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea73b99",
   "metadata": {},
   "source": [
    "# With  RMSprob and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "502f8382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64, 50)            30200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 87,818\n",
      "Trainable params: 87,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"Rmsprob_lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acde8a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 6s 29ms/step - loss: 28.1005 - accuracy: 0.1014 - val_loss: 6.7488 - val_accuracy: 0.1400\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 4.9913 - accuracy: 0.1545 - val_loss: 4.1534 - val_accuracy: 0.1600\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 4s 26ms/step - loss: 3.7764 - accuracy: 0.1867 - val_loss: 3.9269 - val_accuracy: 0.1700\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 4s 26ms/step - loss: 3.4448 - accuracy: 0.2045 - val_loss: 3.9435 - val_accuracy: 0.2300\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 4s 26ms/step - loss: 3.2215 - accuracy: 0.2312 - val_loss: 4.1335 - val_accuracy: 0.1900\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 4s 26ms/step - loss: 3.0990 - accuracy: 0.2433 - val_loss: 3.9438 - val_accuracy: 0.1800\n",
      "Epoch 7/30\n",
      "154/154 [==============================] - 4s 27ms/step - loss: 2.9353 - accuracy: 0.2690 - val_loss: 4.1138 - val_accuracy: 0.1900\n",
      "Epoch 8/30\n",
      "154/154 [==============================] - 4s 26ms/step - loss: 2.8925 - accuracy: 0.2808 - val_loss: 4.0615 - val_accuracy: 0.1800\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcafe620",
   "metadata": {},
   "source": [
    "# With  SGD and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45760146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 64, 100)           400       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64, 50)            30200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 50)            200       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,118\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"sgd_lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6285706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 7s 34ms/step - loss: 3.3547 - accuracy: 0.1867 - val_loss: 2.5118 - val_accuracy: 0.2100\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 1.9984 - accuracy: 0.3949 - val_loss: 2.4229 - val_accuracy: 0.2800\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 1.5653 - accuracy: 0.5078 - val_loss: 2.5726 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 1.3079 - accuracy: 0.5753 - val_loss: 2.8895 - val_accuracy: 0.2600\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 1.1259 - accuracy: 0.6388 - val_loss: 2.8880 - val_accuracy: 0.2800\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 0.9814 - accuracy: 0.6888 - val_loss: 3.3794 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 0.8909 - accuracy: 0.7194 - val_loss: 3.3187 - val_accuracy: 0.2900\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49728a",
   "metadata": {},
   "source": [
    "# With  Adam and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cd6cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 64, 100)           400       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64, 50)            30200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 50)            200       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,118\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"Adam_lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc368ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 7s 34ms/step - loss: 3.1715 - accuracy: 0.1882 - val_loss: 2.3764 - val_accuracy: 0.3300\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 1.8332 - accuracy: 0.4218 - val_loss: 2.3358 - val_accuracy: 0.3000\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 1.4818 - accuracy: 0.5331 - val_loss: 2.4593 - val_accuracy: 0.3000\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 5s 33ms/step - loss: 1.2800 - accuracy: 0.5931 - val_loss: 2.5501 - val_accuracy: 0.3200\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 1.1208 - accuracy: 0.6463 - val_loss: 2.6472 - val_accuracy: 0.3100\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 0.9951 - accuracy: 0.6959 - val_loss: 2.8590 - val_accuracy: 0.3100\n",
      "Epoch 7/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 0.8874 - accuracy: 0.7257 - val_loss: 2.8334 - val_accuracy: 0.3300\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd21e5",
   "metadata": {},
   "source": [
    "# With  RMSprob and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f753dff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 64, 100)           400       \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64, 50)            30200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64, 50)            200       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,118\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"bakr_word2vec\", model_type=\"Rmsprob_lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dae74e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 7s 34ms/step - loss: 13.1241 - accuracy: 0.0931 - val_loss: 20.3543 - val_accuracy: 0.0200\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 9.0058 - accuracy: 0.0986 - val_loss: 21.7042 - val_accuracy: 0.0500\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 8.8351 - accuracy: 0.1061 - val_loss: 12.7319 - val_accuracy: 0.0400\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 8.9997 - accuracy: 0.1010 - val_loss: 20.5070 - val_accuracy: 0.0600\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 9.4414 - accuracy: 0.1033 - val_loss: 10.4307 - val_accuracy: 0.1300\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 10.4542 - accuracy: 0.0924 - val_loss: 9.6145 - val_accuracy: 0.0200\n",
      "Epoch 7/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 9.4937 - accuracy: 0.0924 - val_loss: 12.4146 - val_accuracy: 0.0800\n",
      "Epoch 8/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 9.4293 - accuracy: 0.1002 - val_loss: 20.1759 - val_accuracy: 0.0300\n",
      "Epoch 9/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 9.6838 - accuracy: 0.0882 - val_loss: 18.3428 - val_accuracy: 0.1200\n",
      "Epoch 10/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 9.8457 - accuracy: 0.0865 - val_loss: 14.4819 - val_accuracy: 0.0400\n",
      "Epoch 11/30\n",
      "154/154 [==============================] - 5s 30ms/step - loss: 10.8500 - accuracy: 0.0686 - val_loss: 12.5130 - val_accuracy: 0.0900\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f916503",
   "metadata": {},
   "source": [
    "# LSTM Model with Rezk Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7f928ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c93433c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "(4900, 64, 300)\n",
      "(4900, 19200)\n",
      "==================================================\n",
      "[-0.1262   0.2761   0.2466  -0.3464  -0.5044   0.216    0.2651   0.05423\n",
      " -0.3276  -0.2793   0.328    0.1699  -0.05267  0.1941   0.292    0.1654\n",
      " -0.01619 -0.428    0.411    0.0927   0.271    0.6206  -0.04764  0.04465\n",
      "  0.0863   0.06042  0.08374 -0.0927   0.05176 -0.1616  -0.4875   0.4932\n",
      "  0.1333   0.4666   0.0387  -0.19     0.05563 -0.1526   0.549    0.2966\n",
      " -0.0969  -0.345   -0.2896  -0.0667   0.12146  0.2126   0.1146  -0.4404\n",
      " -0.1198   0.2651 ]\n",
      "==================================================\n",
      "(100, 64, 300)\n",
      "(100, 19200)\n",
      "==================================================\n",
      "[-1.091    0.2328   0.1113  -0.4392   0.687   -0.8223  -0.572   -0.454\n",
      "  0.2      0.3171  -0.5127  -0.2296   0.2198  -0.07245 -0.548    0.3447\n",
      "  0.2394   0.2744   0.497   -1.322   -0.6577   0.294    0.965    0.6753\n",
      "  0.6943   0.0327  -1.08    -0.3694  -0.4783   0.351    0.7593   0.07\n",
      " -0.284   -0.422   -0.639    0.405    0.7314  -0.171   -0.0849   0.1683\n",
      "  1.39    -1.2     -0.631   -0.5005   0.748   -0.698    0.542   -0.6484\n",
      " -0.12427 -0.607  ]\n"
     ]
    }
   ],
   "source": [
    "number_of_features = 300\n",
    "\n",
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "\n",
    "word2vec_path = \"rezk/\"\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "\n",
    "# Reshape because of deep learning model\n",
    "X_train_embed_matrix = X_train_embed_matrix.reshape(X_train_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "X_val_embed_matrix = X_val_embed_matrix.reshape(X_val_embed_matrix.shape[0], max_len_str, number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c18ec",
   "metadata": {},
   "source": [
    "# With  SGD and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f221477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 64, 50)            70200     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 127,818\n",
      "Trainable params: 127,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"sgd_lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b237c4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 7s 37ms/step - loss: 2.7574 - accuracy: 0.1484 - val_loss: 2.6179 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 5s 33ms/step - loss: 2.5406 - accuracy: 0.2294 - val_loss: 2.4228 - val_accuracy: 0.2400\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 5s 34ms/step - loss: 2.3578 - accuracy: 0.2694 - val_loss: 2.2620 - val_accuracy: 0.2600\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 5s 35ms/step - loss: 2.2158 - accuracy: 0.3037 - val_loss: 2.1814 - val_accuracy: 0.2900\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 5s 34ms/step - loss: 2.1019 - accuracy: 0.3292 - val_loss: 2.1751 - val_accuracy: 0.2600\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 2.0112 - accuracy: 0.3496 - val_loss: 2.3050 - val_accuracy: 0.2600\n",
      "Epoch 7/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.9406 - accuracy: 0.3802 - val_loss: 2.0963 - val_accuracy: 0.3300\n",
      "Epoch 8/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.8784 - accuracy: 0.3986 - val_loss: 2.0594 - val_accuracy: 0.3100\n",
      "Epoch 9/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.8231 - accuracy: 0.4163 - val_loss: 2.2586 - val_accuracy: 0.2800\n",
      "Epoch 10/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.7706 - accuracy: 0.4347 - val_loss: 2.2651 - val_accuracy: 0.3200\n",
      "Epoch 11/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.7125 - accuracy: 0.4604 - val_loss: 2.2163 - val_accuracy: 0.3300\n",
      "Epoch 12/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.6581 - accuracy: 0.4749 - val_loss: 2.2963 - val_accuracy: 0.3200\n",
      "Epoch 13/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.6042 - accuracy: 0.4945 - val_loss: 2.0268 - val_accuracy: 0.3200\n",
      "Epoch 14/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.5478 - accuracy: 0.5151 - val_loss: 2.2938 - val_accuracy: 0.3500\n",
      "Epoch 15/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.4984 - accuracy: 0.5271 - val_loss: 2.1202 - val_accuracy: 0.3900\n",
      "Epoch 16/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.4443 - accuracy: 0.5365 - val_loss: 2.3588 - val_accuracy: 0.3000\n",
      "Epoch 17/30\n",
      "154/154 [==============================] - 5s 33ms/step - loss: 1.3878 - accuracy: 0.5631 - val_loss: 2.2284 - val_accuracy: 0.3500\n",
      "Epoch 18/30\n",
      "154/154 [==============================] - 6s 38ms/step - loss: 1.3464 - accuracy: 0.5794 - val_loss: 2.2783 - val_accuracy: 0.3100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e2919",
   "metadata": {},
   "source": [
    "# With  Adam and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54bb77d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 64, 50)            70200     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 127,818\n",
      "Trainable params: 127,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"Adam_lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67eaf867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 9s 43ms/step - loss: 2.3610 - accuracy: 0.2592 - val_loss: 2.0594 - val_accuracy: 0.3000\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 8s 52ms/step - loss: 1.8890 - accuracy: 0.3982 - val_loss: 1.9170 - val_accuracy: 0.3600\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 9s 60ms/step - loss: 1.6939 - accuracy: 0.4563 - val_loss: 1.8842 - val_accuracy: 0.3500\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 7s 46ms/step - loss: 1.5359 - accuracy: 0.5112 - val_loss: 1.8664 - val_accuracy: 0.3900\n",
      "Epoch 5/30\n",
      "154/154 [==============================] - 5s 35ms/step - loss: 1.4031 - accuracy: 0.5516 - val_loss: 1.8713 - val_accuracy: 0.3700\n",
      "Epoch 6/30\n",
      "154/154 [==============================] - 6s 37ms/step - loss: 1.2765 - accuracy: 0.5990 - val_loss: 1.9142 - val_accuracy: 0.4200\n",
      "Epoch 7/30\n",
      "154/154 [==============================] - 5s 35ms/step - loss: 1.1719 - accuracy: 0.6302 - val_loss: 1.9494 - val_accuracy: 0.3400\n",
      "Epoch 8/30\n",
      "154/154 [==============================] - 5s 32ms/step - loss: 1.0615 - accuracy: 0.6718 - val_loss: 1.9967 - val_accuracy: 0.3700\n",
      "Epoch 9/30\n",
      "154/154 [==============================] - 6s 37ms/step - loss: 0.9694 - accuracy: 0.6927 - val_loss: 2.0971 - val_accuracy: 0.3700\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cfd06",
   "metadata": {},
   "source": [
    "# With  Rmsprob and No Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e698050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 64, 50)            70200     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 18)                57618     \n",
      "=================================================================\n",
      "Total params: 127,818\n",
      "Trainable params: 127,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"Rmsprob_lstm_no_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_no_batch_seqential_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e18c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "154/154 [==============================] - 7s 35ms/step - loss: 3.7504 - accuracy: 0.1912 - val_loss: 2.7484 - val_accuracy: 0.2400\n",
      "Epoch 2/30\n",
      "154/154 [==============================] - 6s 37ms/step - loss: 2.1191 - accuracy: 0.3633 - val_loss: 2.7736 - val_accuracy: 0.2300\n",
      "Epoch 3/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.6886 - accuracy: 0.4867 - val_loss: 2.9992 - val_accuracy: 0.2600\n",
      "Epoch 4/30\n",
      "154/154 [==============================] - 5s 31ms/step - loss: 1.3692 - accuracy: 0.5747 - val_loss: 3.3729 - val_accuracy: 0.2800\n",
      "Epoch 5/30\n",
      "119/154 [======================>.......] - ETA: 1s - loss: 1.0784 - accuracy: 0.6549"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e03d9f",
   "metadata": {},
   "source": [
    "# With  SGD and  Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"sgd_lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, SGD_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044655d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a2c80",
   "metadata": {},
   "source": [
    "# With  Adam and  Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"Adam_lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, Adam_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dc2268",
   "metadata": {},
   "source": [
    "# With  Rmsprob and  Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_ = keras_callbacks(word2vec_type=\"rezk_word2vec\", model_type=\"Rmsprob_lstm_with_batch\", learning_rate=learning_rate)\n",
    "callbacks_.append(performance_lr)\n",
    "model = lstm_with_batch_model_create(hid_num_neurons, max_len_str, number_of_features, dropout=.2)\n",
    "model = seqential_model_compile(model, RMSprop_optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a9f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_embed_matrix, y_train, batch_size=32, epochs=epochs, validation_data=(X_val_embed_matrix, y_val),\n",
    "                   callbacks=callbacks_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
