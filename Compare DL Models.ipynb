{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6391533c",
   "metadata": {},
   "source": [
    "# Note !\n",
    "\n",
    "**You can see the difference between deep learning models in your web browser from write that below line in terminal**\n",
    "\n",
    "\n",
    "\"tensorboard --logdir=./models/dl_models/tensor_logs --port=6006\"\n",
    "\n",
    "# Or run cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c0a2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-aa5b1764488636e9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-aa5b1764488636e9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./models/dl_models/tensor_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_shuffling_split import *\n",
    "from features_extraction import *\n",
    "from data_preprocess import *\n",
    "from ml_modeling import *\n",
    "from keras_models import *\n",
    "from configs import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54cf3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_score(model, x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    \n",
    "    print(\"On Training set\\n\")\n",
    "    keras_f1_score_result(model, x_train, y_train)\n",
    "    print(\"=\"*50)\n",
    "    print(\"On Validation set \\n\")\n",
    "    keras_f1_score_result(model, x_val, y_val)\n",
    "    print(\"=\"*50)\n",
    "    print(\"On Training \\n\")\n",
    "    keras_f1_score_result(model, x_test, y_test)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a219e642",
   "metadata": {},
   "source": [
    "# Tokenize All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f72830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation data\n",
    "strat_train_set = read_csv(\"train/strat_train_set.csv\")\n",
    "x_train_text, x_val_text, y_train, y_val = prepare_data(strat_train_set)\n",
    "\n",
    "# Test\n",
    "strat_test_set = pd.read_csv(\"dataset/test/strat_test_set.csv\")\n",
    "x_test_text, y_test = list(strat_test_set['text']), strat_test_set['dialect_l_encoded'].values\n",
    "\n",
    "\n",
    "x_train_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_train_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_train_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_train_text_tokenized[:3])\n",
    "print(\"=\"*50)\n",
    "\n",
    "x_val_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_val_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_val_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_val_text_tokenized[:3])\n",
    "\n",
    "\n",
    "x_test_text_tokenized = tokenize_using_nltk_TreebankWordTokenizer(x_test_text)\n",
    "\n",
    "print(\"Before Tokenization : \\n\", x_test_text[:3])\n",
    "print(\"=\"*50)\n",
    "print(\"After Tokenization : \\n\", x_test_text_tokenized[:3])\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3033ef1d",
   "metadata": {},
   "source": [
    "# Abo Bakr Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8fa7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 100\n",
    "max_len_str = 64\n",
    "\n",
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/bakrianoo_unigram_cbow_model/full_uni_cbow_100_twitter.mdl\")\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "x_test_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_test_text_tokenized, max_len_str)\n",
    "\n",
    "# Reshape because of deep learning model\n",
    "X_train_embed_matrix = X_train_embed_matrix.reshape(X_train_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "X_val_embed_matrix = X_val_embed_matrix.reshape(X_val_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "x_test_embed_matrix = x_test_embed_matrix.reshape(x_test_embed_matrix.shape[0], max_len_str, number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfce339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using Adam_lstm_no_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_bakr_word2vec_Adam_lstm_no_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4689e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using Adam_lstm_with_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_bakr_word2vec_Adam_lstm_with_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using Rmsprob_lstm_with_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_bakr_word2vec_Rmsprob_lstm_with_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d9fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using RMSprop_lstm_no_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_bakr_word2vec_RMSprop_lstm_no_with_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using sgd_lstm_no_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_bakr_word2vec_sgd_lstm_no_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using sgd_lstm_with_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_bakr_word2vec_sgd_lstm_with_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f52585",
   "metadata": {},
   "source": [
    "#  Rezk Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features = 300\n",
    "max_len_str = 64\n",
    "\n",
    "word2vec_path = \"rezk_unigram_CBOW_model/train_word2vec_cbow__window_3_min_count_300\"\n",
    "word_to_vec_model = load_word2vec_model(\"models/word2vec/\" + word2vec_path)\n",
    "\n",
    "X_train_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_train_text_tokenized, max_len_str)\n",
    "X_val_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_val_text_tokenized, max_len_str)\n",
    "x_test_embed_matrix = text_to_matrix_using_word2vec(word_to_vec_model, x_test_text_tokenized, max_len_str)\n",
    "\n",
    "# Reshape because of deep learning model\n",
    "X_train_embed_matrix = X_train_embed_matrix.reshape(X_train_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "X_val_embed_matrix = X_val_embed_matrix.reshape(X_val_embed_matrix.shape[0], max_len_str, number_of_features)\n",
    "x_test_embed_matrix = x_test_embed_matrix.reshape(x_test_embed_matrix.shape[0], max_len_str, number_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e065d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using Adam_lstm_no_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_rezk_word2vec_Adam_lstm_no_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using Adam_lstm_with_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_rezk_word2vec_Adam_lstm_with_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using RMSprop_lstm_no_batch\n",
    "model_path    = \"models/dl_models/run_with_rezk_word2vec_Rmsprob_lstm_no_batch_learning_rate=0.1__model.h5\"\n",
    "\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using Rmsprob_lstm_with_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_rezk_word2vec_Rmsprob_lstm_with_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1663dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using sgd_lstm_no_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_rezk_word2vec_sgd_lstm_no_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using sgd_lstm_with_batch\n",
    "\n",
    "model_path    = \"models/dl_models/run_with_rezk_word2vec_sgd_lstm_with_batch_learning_rate=0.1__model.h5\"\n",
    "model = keras_load_model(model_path)\n",
    "\n",
    "_ = train_val_test_score(model, X_train_embed_matrix, y_train, X_val_embed_matrix, y_val, \n",
    "                         x_test_embed_matrix, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659bf786",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "If we compare the model prediction to the human prediction, we may conclude that the task of predict the dialect is semi difficult task for human. So how its if we that compare to the model !.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
